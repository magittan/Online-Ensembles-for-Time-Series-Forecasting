{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tricky Ideas:\n",
    "- Need to maintain a notion of time from initialization for training\n",
    "- Need to maintain a notion of time while fitting and initializing\n",
    "\n",
    "Use Cases would be:\n",
    "- Train on a bunch of losses\n",
    "- Train on a bunch of losses, then iteratively predict and train at each time step \n",
    "- Train on a bunch of losses, then iteratively predict and train at each time step "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases not considered:\n",
    "- Features coming in at unequal times (in this case we would need to sample the data at equal times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.princeton.edu/~rlivni/cos511/lectures/lect18.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "def se(actual,expected):\n",
    "    \"\"\"\n",
    "    Will return the squared error between the two arguments\n",
    "    \"\"\"\n",
    "    return np.power(np.subtract(actual,expected),2)\n",
    "\n",
    "def mse(actual,expected):\n",
    "    \"\"\"\n",
    "    Will return the mean squared error between the two arguments\n",
    "    \"\"\"\n",
    "    return np.mean(se(actual,expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _choose_from_distribution(axis_weights,sample_size=1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        axis_weights: np.array() 1-D Array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array() with indices chosen according to the probability distribution defined by the axis weights\n",
    "\n",
    "        Functional Code\n",
    "        ---------------\n",
    "            weights = abs(np.random.randn(10))\n",
    "            weights/=np.sum(weights)\n",
    "            bins = np.cumsum(weights)\n",
    "            selections = np.random.uniform(size=10)\n",
    "\n",
    "        Test Code\n",
    "        ---------\n",
    "            a = choosing_with_respect_to_prob_dist([1,2,3],sample_size=10000)\n",
    "            print(\"Should be around .16: {}\".format(np.sum(a==0)/10000))\n",
    "            print(\"Should be around .33: {}\".format(np.sum(a==1)/10000))\n",
    "            print(\"Should be around .50: {}\".format(np.sum(a==2)/10000))\n",
    "        \"\"\"\n",
    "        weights = axis_weights/np.sum(axis_weights)\n",
    "        bins = np.cumsum(weights)\n",
    "\n",
    "        selections = np.random.uniform(size=sample_size)\n",
    "        indices = [bisect.bisect_left(bins,s) for s in selections]\n",
    "\n",
    "        return np.array(indices)\n",
    "    \n",
    "def _set_uniform(n):\n",
    "        return np.ones(n)/n\n",
    "    \n",
    "def _define_epsilon(n,T,a=1):\n",
    "    \"\"\"\n",
    "    Calculates a factor that is used in determining loss in the hedge algorithm\n",
    "\n",
    "    Args:\n",
    "        n (int): number of experts present\n",
    "        T (int): number of time steps taken\n",
    "        a (float): value that we can use to scale our epsilon\n",
    "    Return:\n",
    "        epsilon (float): the theoretical episilon, but which can be customized by a\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.log(n)/T)*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineHedge(object):\n",
    "\n",
    "    def __init__(self,n=10,T=10,a=1):\n",
    "        self.n = n\n",
    "        self.T = T\n",
    "        self.a = a\n",
    "        self.weights = _set_uniform(n)\n",
    "        self.epsilon = _define_epsilon(self.n,self.T,a=a)\n",
    "        \n",
    "        self.time = 0\n",
    "        \n",
    "    def _predict(self,expert_predictions):\n",
    "        \"\"\"\n",
    "        Weights the expert predictions into a single prediction based on the weights that have been calculated by the\n",
    "        hedge algorithm\n",
    "\n",
    "        Args:\n",
    "            expert predictions (np.array) (pred.float): np.array with the expert predictions\n",
    "\n",
    "        Returns:\n",
    "            a value for prediction based on the inputs of the experts and their respective weights.\n",
    "        \"\"\"\n",
    "        choosen_prediction = expert_predictions[_choose_from_distribution(self.weights,sample_size=1)]\n",
    "        \n",
    "        return chosen_prediction\n",
    "    \n",
    "    def _update(self, expert_predictions, actual_values, loss_func = se):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert expert_predictions.shape[1]==len(actual_values), \"Time Dimension Matches\"\n",
    "        time_length = expert_predictions.shape[1]\n",
    "        \n",
    "        total_time = time_length+self.time\n",
    "        \n",
    "        a = int(np.floor(np.log2(total_time/self.T)))\n",
    "        splits = [self.T*2**(i)-self.time for i in range(a)]\n",
    "        # negative indices are ignored\n",
    "        splits = list(filter(lambda x: x>=0,splits))\n",
    "        partitions = np.split(np.arange(total_time-self.time),splits)\n",
    "        \n",
    "        for i in range(len(partitions)):\n",
    "            self.time+=len(partitions[i])\n",
    "            \n",
    "            print(partitions[i])\n",
    "            print(self.time)\n",
    "            \n",
    "            if self.time>self.T:\n",
    "                self.T = 2*self.T\n",
    "                self.epsilon = _define_epsilon(self.n,self.T,self.a)\n",
    "                \n",
    "            losses = np.array([loss_func(expert_predictions[:,part], actual_values[part]) for part in partitions[i]])\n",
    "            f = lambda x: np.exp(-self.epsilon*x)\n",
    "            self._modify_weights(np.prod(f(losses),0))\n",
    "        \n",
    "    def _modify_weights(self,new_array):\n",
    "        self.weights = self.weights * new_array\n",
    "        self.weights /= np.sum(self.weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = OnlineHedge(n=10,T=20,a=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_predictions = np.random.randn(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values = np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "test1._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "test2 = OnlineHedge(n=10,T=20,a=1)\n",
    "expert_predictions = np.random.randn(10,20)\n",
    "actual_values = np.random.randn(20)\n",
    "test2._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "test2._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23992629560940407"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = OnlineHedge(n=10,T=20,a=1)\n",
    "expert_predictions = np.random.randn(10,20)\n",
    "actual_values = np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "test3._fit(expert_predictions,actual_values)\n",
    "test3._fit(expert_predictions,actual_values)\n",
    "test3._fit(expert_predictions,actual_values)\n",
    "test3._fit(expert_predictions,actual_values)\n",
    "test3._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0848267553051889"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Epsilon Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = OnlineHedge(n=10,T=20,a=1)\n",
    "expert_predictions = np.random.randn(10,13)\n",
    "actual_values = np.random.randn(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "test4._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "test4._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_predictions = np.random.randn(10,14)\n",
    "actual_values = np.random.randn(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "test4._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23992629560940407"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_predictions = np.random.randn(10,40)\n",
    "actual_values = np.random.randn(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "40\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "test4._fit(expert_predictions,actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1696535106103778"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4.epsilon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
